{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py as h\n",
    "import fnmatch as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"nreo.hdf5\"#\"../2022-01-01_Scan/nreo_NR_both_diver_c15_only_Halo_WW/samples/nreo.hdf5\"\n",
    "rawH5 = h.File(filename, \"r\")\n",
    "namesplit = filename.split(\"_\")\n",
    "coupling = 4#int(namesplit[namesplit.index(\"diver\")+1].strip(\"c\"))\n",
    "# rawH5[\"nreo\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalloglike = \"LogLike\"\n",
    "# loglikes = fm.filter((fm.filter(rawH5[\"nreo\"].keys(), \"*_Log*\")), \"[!Runtime]*_isvalid\")\n",
    "# loglikes = [s.replace(\"_isvalid\", \"\") for s in loglikes]#.append(\"#IC79_loglike @DarkBit::IC79_loglike\")\n",
    "# loglikes.append(\"#IC79_loglike @DarkBit::IC79_loglike\")\n",
    "# print(len(loglikes), loglikes)\n",
    "# priorlikes = fm.filter((fm.filter(rawH5[\"nreo\"].keys(), \"*lnL_*\")), \"[!Runtime]*[!id]\")\n",
    "# print(len(priorlikes), priorlikes)\n",
    "subloglike = ['#CDMSlite_LogLikelihood @DarkBit::CDMSlite_GetLogLikelihood', '#CRESST_II_LogLikelihood @DarkBit::CRESST_II_GetLogLikelihood', '#DarkSide_50_LogLikelihood @DarkBit::DarkSide_50_GetLogLikelihood', '#LUX_2016_LogLikelihood @DarkBit::LUX_2016_GetLogLikelihood', '#PICO_60_2017_LogLikelihood @DarkBit::PICO_60_2017_GetLogLikelihood', '#PandaX_2016_LogLikelihood @DarkBit::PandaX_2016_GetLogLikelihood', '#PandaX_2017_LogLikelihood @DarkBit::PandaX_2017_GetLogLikelihood', '#XENON1T_2018_LogLikelihood @DarkBit::XENON1T_2018_GetLogLikelihood', '#IC79_loglike @DarkBit::IC79_loglike', '#lnL_rho0 @DarkBit::lnL_rho0_lognormal', '#lnL_v0 @DarkBit::lnL_v0_gaussian', '#lnL_vesc @DarkBit::lnL_vesc_gaussian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(rawH5[\"nreo/\"+totalloglike])):\n",
    "#     total = rawH5[\"nreo/\"+totalloglike][i]\n",
    "#     summation = 0\n",
    "#     print(\"Total: \"+str(total), end=\"\\t\")\n",
    "#     for sublike in subloglike:\n",
    "#         summation = summation + rawH5[\"nreo/\"+sublike][i]\n",
    "#     print(\"Summation: \"+str(summation), end=\"\\t\")\n",
    "#     print(\"Diff: \"+str(total-summation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"nreo_NR_both_diver_c4_only_Halo_WW.dat\"\n",
    "H5file = \"nreo.hdf5\"\n",
    "print(\"Step 1\")\n",
    "pointID, logL, v0, vesc, rho0, dmMass, c0_i, newANTARES, newIceCube = np.loadtxt(filename, dtype=float).T\n",
    "print(\"Step 2\")\n",
    "appendingH5 = h.File(H5file, \"a\")\n",
    "print(\"Step 3\")\n",
    "points = appendingH5[\"nreo/pointID\"]\n",
    "length = len(points)\n",
    "completeANTARES = np.zeros(length, dtype=float)\n",
    "completeIceCube = np.zeros(length, dtype=float)\n",
    "modifiedLike = np.zeros(length, dtype=float)\n",
    "ANTARES_isvalid = np.zeros(length, dtype=int)\n",
    "IceCube_isvalid = np.zeros(length, dtype=int)\n",
    "modifiedLike_isvalid = np.zeros(length, dtype=int)\n",
    "for i in range(len(points)):\n",
    "    point = i+1\n",
    "    if point in pointID:\n",
    "        indexPoint = np.where(pointID == point)[0][0]\n",
    "        completeANTARES[i] = newANTARES[indexPoint]\n",
    "        ANTARES_isvalid[i] = 1\n",
    "        completeIceCube[i] = newIceCube[indexPoint]\n",
    "        IceCube_isvalid[i] = 1\n",
    "        modifiedLike[i] = logL[indexPoint] + newANTARES[indexPoint] + newIceCube[indexPoint]\n",
    "        modifiedLike_isvalid[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFilename = os.path.splitext(filename)[0]+\"-extracted.dat\"\n",
    "with open(outputFilename, mode=\"w\") as file:\n",
    "    file.write(\"pointID logL v0 vesc rho0 dmMass c0_i\\n\")\n",
    "    for i in range(len(logL)):\n",
    "        file.write(np.array(pointID_valid).astype(str)[i]+\" \")\n",
    "        file.write(np.array(logL_valid).astype(str)[i]+\" \")\n",
    "        file.write(np.array(v0_valid).astype(str)[i]+\" \")\n",
    "        file.write(np.array(vesc_valid).astype(str)[i]+\" \")\n",
    "        file.write(np.array(rho0_valid).astype(str)[i]+\" \")\n",
    "        file.write(np.array(dmMass_valid).astype(str)[i]+\" \")\n",
    "        file.write(np.array(c0_valid).astype(str)[i]+\" \")\n",
    "        file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
